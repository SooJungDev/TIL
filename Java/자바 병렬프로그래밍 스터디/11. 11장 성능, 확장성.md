## 11장 내용
- 11.1 성능에 대해
- 11.2 암달의 법칙
- 11.3 스레드와 비용
- 11.4 락 경쟁 줄이기
- 11.5 예제: Map 객체의 성능 분석
- 11.6 컨텍스트 스위치 부하 줄이기

## 11.1 성능에 대해
- 스레드를 사용하는 가장 큰 목적은 바로 성능을 높이고자 하는 것이다.
- 스레드를 사용하면 시스템의 자원을 훨씬 효율적으로 활용 할 수 있고, 어플리케이션으로 하여금 시스템이 갖고 있는 능력을 최대한 사용하게 할 수 있다.
- 그와 동시에 기존 작업이 실행되고 있는 동안에라도 새로 등록된 작업을 즉시 실행할 수 있는 준비를 갖추고 있기 때문에 애플리케이션의 응답 속도를 향상 시킬 수 있다.
- 11장에서는 병렬프로그래밍의 성능을 분석하고, 모니터링하고, 그결과로 성능을 향상 시킬 수 있는 방법에 대해 알아본다.
- 프로그램이 정상적으로 동작하도록 만들어 놓고 난 다음 프로그램이 빠르게 동작하도록 만드는 편이 낫다고 본다.
- 예상했던 성능 기준이 있엇다면, 그기준에 미치지 못할 경우에만 성능 문제를 살펴보는것도 충분하다.
- 병렬 어플리케이션을 성계하는 동안에는 성능을 최대한으로 끌어 올리는 일이 큰 부분을 차지하지 않을때가 많다.

- 성능을 높인다는것은 더 적은 자원을 사용하면서 더많은 일을 하도록 한다는 말
- 자원이라는 단어에는 여러 가지 뜻이 있을 수 있는데, 처리해야 할 작업이 있을대 CPU, 메모리, 네트웍속도, 디스크속도, 데이터베이스 처리속도, 디스크 용량등의 자원 가운데 어느것이 될지 모르지만 항상 모자라는 부분이 발생할것이다.
- 어떤 작업을 실행 할 때 충분하지 못한 특정 자원 때문에 성능이 떨어지는 현상이 나타난다면, 작업의 성능이 해당 자원에 좌우된다고 한다.
    - CPU에 좌우 될 수 도 있고, 데이터베이스 속도에 좌우될 수 도 있다.
- 여러개의 스레드를 사용하려면 항상 단일 스레드를 사용할때보다 성능상의 비용을 지불해야만 한다
    - 스레드간의 작업 내용을 조율하는데 필요한 오버헤드
    - 컨텍스트 스위칭이 자주 발생한다는점
    - 스레드를 생성하거나 제거하는 일이 빈번하다는점
    - 여러 스레드를 효율적으로 스케쥴링 해야되는것 모두 비용
- 이와 같은 비용을 지불한다고 해도 스레드를 효율적으로 잘 적용하면 성능이나 응답성이 높아지고 처리 용량도 커지는 여러 장점을 얻을 수 있다.
- 반대로 잘못 설계된 병렬 어플리케이션은 순차적으로 작업을 처리하는 프로그램보다 오히려 느리게 동작하는 경우도 간혹 생긴다.

더나은 성능을 목표로 해서 프로그램이 병렬로 동작하도록 만들 때는 두가지 부분을 우선적으로 생각해야한다.
- 프로그램이 확보 할 수 있는 모든 자원을 최대한 활용해야하고, 남는 자원이 생길때마다 그 자원 역시 대한 활용할 수 있도록 해야한다
- 프로그램의 성능을 모니터링하는 관점에서 얘기해보자면, 앞에서 언급한 부분은 CPU가 최대한 바쁘게 동작해야 한다는것과 동일하게 생각 할 수 있다.
- 프로그램에서최 스레드를 활용하면 작업을 자게 나눠 시스템에 꽂힌 CPU 가 충분히 열심히 동작해야 할 만큼의 작업을 싱행시켜 노는 CPU가 없을 만큼 작업 실행 성능을 높일 수 있다.

### 성능 대 확장성
성능 대 확작성
- 애플리케이션의 성능은 여러가지 측면에서 자료를 수집해 측정할 수 있는데, 이를테면 서비스 시간, 대기시간, 처리량, 효율성, 확장성, 용량 등의 수치를 뽑아 낼 수 있다.
    - 특정 작업을 처리하는 속도가 얼마나 빠르냐
    - 동일한 자원을 갖고 있을 때 얼마나 많은 양의 일을 할 수 있는지
- **확장성은 CPU, 메모리, 디스크 , I/O 처리 장치등의 추가적인 장비를 사용해 처리량이나 용량을 얼마나 쉽게 키울 수 있는지를 말한다.**
- 확장성을 목표로 튜닝을 한다면 처리해야 할 작업을 병렬화해 시스템의 가용 자원을 더 많이 끌어다 사용하면서 더 많은 일을 처리 할 수 있도록 하는 방법을 많이 사용하게 된다.
- 이처럼 성능이라는 단어에 포함된 얼마나 빠르게와 얼마나 많이라는 두가지의 의미는 완전히 다른뜻을 가지며, 어떤경우에는 화합할수 없는 상황도 발생
- 단일 스레드 어플리케이션에서 사용하던 성능방안은 대부분 확장성 측면에서 효과적이지 않다.
- 3티어모델(프레제이션티어,비지니스로직티어,스토리지 티어)을 보면 시스템 확장성을 높이도록 변경할때 성능의 측면에서 얼마나 많은 손해를 보년경우가 많은지 쉽게 알수 있다.
- 단일 어플리케이션이 성능이 훨씬 나을 가능성이 많음
    - 네트워크 지연현상 X
    - 연산작업을 서로 다른 추상적인 계층을 통과시키가며 처리하는데 드는 부하가 적기때문에
- 단일구조 어플리케이션 처리할수 있는 최대부하를 넘어서는 작업량을 감당해야하는 순간이오면 문제 심각
    - 처리용량을 단시간에 급격하게 증가시키는 일 어려움
    - 시스템 자원을 계속투입, 서비스 시간이 훨씬 길어지거나 단위 작업당 필요한 하드웨어 자원의 양을 크게 늘어나는 일 감수
- 서버 어플리케이션을 만들때는 성능의 여러가지 측면까운데 얼마나 빠르게라는 측면보다 얼마나 많이 라는 측명 즉 확장성과 처리량과 용량이라는 세개의 측면을 훨씬 중요하게 생각하는 경우 많다
    - 사용자와의 직접적인 사용하 작용이 일어나는 어플리케이션이라면 대기시간이라는 값이 중요
    - 대기시간을 줄여야 사용자가 진행하는 상태를 보며 실제로 무슨일이 일어나는지 기다리는 시간이 줄어듬
- 11장에서는 단일스레드 상황에서 성능보다는 확장성을 중점적으로 다룬다
  
### 성능 트레이드 오프 측정
- 공학적인 모든 선택의 순간에는 항상 트레이드 오프가 존재
- ex) 다리 건설 튼튼하게 지으면 안정성 높아지지만 돈많이듬
- 트레이드 오프에서 어떤부분을 선택해야 할지 결정하는데 필요한 정보가 그다지 충분하지 않은 경우가 많음
- ex) 퀵소트 알고리즘 대량의 자료를 정렬할때는 효율 자료의 양의 많지않을때는 버블소트 알고리즘이 더 효율적임
    - 요구사항에 따라 효율적인게 달라짐
- 요구사항을 충분히 받지 못해 정확하게 구현하지 못한 상태에서 효과가 없다고 판단하는 경우가 많ㅇ끼때문에 최적화 기법을 잘 적용하지 못하는 원인이됨
- **최적화 기법을 너무 이른 시점에 적용하지 말아야한다. 일단 제대로 동작하게 만들고 난 다음에 빠르게 동작하도록 최적화 해야하며, 예상한것보다 심각하게 성능이 떨어지는 경우에만 최적화 기법을 적용하는것으로 충분하다.**
- 공학적인 결정을 내려야하는 시점에는 어떤 효과를 얻고자 할때 다른 비용을 지출해야만 할수 있고, 또 어떤 경우에는 안정성을 확보하기 위해 비용을 지불해야 될수도 있다
- 성능을 높이기 위한 대부분의 결정사항에는 다양한 변수가 관여하곤 하고 처한 상황에 따라 결정사항이 크게 달라진다.
  
다음과 같은 질문에 답할 필요가 있음
- 빠르다 단어가 무엇을 의미하는가?
- 어떤 조건을 갖춰야 이방법이 실제로 빠르게 동작할것인가? 부하가 적을때? 아니면 부하가 걸릴때? 데이터가 많을때? 아니면 적을때? 이런질문에 대한 대답에 명확한 수치를 보여줄수 있는가?
- 위의 조건에 해당하는 경우가 얼마나 많이 발생하는가? 이런질문에 대한 대답에 명확한 수치를 보여줄수 있는가?
- 조건이 달라지는 다른 상황에서도 같은 코드를 사용할수 있는가?
- 이방법으로 성능을 개선하고자 할때 숨겨진 비용, 즉 개발 비용이나 유지보수 비용이 증가하는 부분이 어느정도인지? 과연 그런 비용을 감수하면서 까지 성능 개선작업을 해야하는가?

- 병렬프로그래밍에서 발생하는 오류의 가장큰원인이 바로 성능을 높이려는 여러가지 기법에서 비롯된다고 봐도 무리가아니다.
- 버그의 원인이 될 가능성이 조금이라도 있는 위험도 높은 코드는 매우 주의깊게 살펴봐야한다.
- 성능을 높이기위해 안전성을 떨어뜨리는것은 최악의 상황이며, 결국 안전성과 성능 둘다 놓치는 결과를 얻는다.
- 따라서 성능을 튜닝하는 모든 과정에 항상 성능 목표에 대한 명확한 요구사항이 있어야한다
- 어느 부분 튜닝, 어느 시점에서 튜닝 그만둬야하는지 판단 할 수 있다.
- 실제와 같은 사용자 부하의 특성을 동일하게 나타낼 수 있는 성능 측정 도구가 있어야한다.
- 그리고 성능 튜닝 후 원하는 목표치를 달성했는지 다시한번 측정값을 뽑아야 한다.
- **추측하지 말고 실제로 측정해보라**

- 시장에 나온 성능 측정용 제품을 보면 소프트웨어 성능을 세밀하게 측정해주고 성능을 떨어뜨리는 병목이 어디에 있는지 눈으로 직접 볼수 있게 해준다.
- 예를들어 perfbar

## 11.2 암달의 법칙
- 일부 작업은 자원을 많이 투입하면 더 빨리 처리 할 수 있다.
    - ex) 곡식을 추수 할땐
- 대부분 병렬 프로그램에는 병렬화 할 수 있는 작업과 순차적으로 처리해야 하는 작업이 뒤섞인 단위 작업의 덩어리를 갖고 있다. 암달의 법칙을 사용하면 병렬의 작업과 순차적의 비율에 따라 하드웨어 자원을 추가로 투입했을때 이론적으로 속도가 얼마나 빨라질지에 대한 예측값을 얻을 수 잇다.
- 암달의 법칙에 따르면 순차적으로 실행돼야 하는 작업의 비율을 F 라고 하고 하드웨어에 꽂혀있는 프로세서의 개수를 N이라고 할때 수식에 해당하는 정도까지 속도를 증가 시킬수 있다.
- N이 무한대까지 증가할수록 속도 증가량은 최고 1/F까지 증가한다.
- 1/F 라는 속도증가량은 순차적으로 실행돼야 하는 부분이 전체 작업 50%를 차지한다고 할때 프로세서를 아무리 많이 꽂는다해도 겨우 두배 빨라진다는 결과
- 그리고 순차적으로 실행해야 하는 부분이 전체의 10% 해당한다면 최고 10배의 속도를 증가 시킬 수 있다고 예측할 수 있다.
- 암달의 법칙을 활용하면 자업을 순차적으로 처리하는 부분이 많아 질때 느려지는 정도가 얼마만큼인지 수치화 할 수 있다.
- ex) 하드웨어 CPU 가 10개 꽂혀있을때 10% 순차작업을 갖고 있는 프로그램은 최고 5.3배 만큼 속도를 증가
    - cpu 활용도는 5.3배/10 = 0.53 즉 53% 시킬수 있다
- ex) 하드웨어 CPU 가 100개 꽂혀있을때 10% 순차작업을 갖고 있는 프로그램은 최고 9.2배 만큼 속도를 증가
    - cpu 활용도는 9.2배/100 = 0.092 즉 9.2% 시킬수 있다
- 속도를 최대 10배 까지 증가시키려면 CPU 활용도가 너무나 비효율적으로 떨어질수 밖에 없음

![KakaoTalk_Photo_2021-06-12-15-46-59](https://user-images.githubusercontent.com/38197944/121767774-76e1b080-cb95-11eb-9060-eb5434f49569.jpeg)
- 암달의 법칙에 따르면 프로세서의 개수가 증가하면 할수록 순차적으로 실행해야하는 부분이 아주 조금이라도 늘어나면 프로세서 개수에 비해 얻을 수 있는 속도 증가량이 크게 떨어진다.
- 멀티 프로세서 시스템에서 어플리케이션을 실행 할 때 속도가 얼마만큼 빨리질것인지 예측해보려면 내부에서 순차적으로 처리해야 하는 작업이 얼마나 되는지 먼저 확인해야한다.

~~~java
public class WorkerThread extends Thread {
    private final BlockingQueue<Runnable> queue;

    public WorkerThread(BlockingQueue<Runnable> queue) {
        this.queue = queue;
    }

    public void run() {
        while (true) {
            try {
                Runnable task = queue.take();
                task.run();

            } catch (InterruptedException e) {
                break; /*스레드를 종료시킨다.*/
            }
        }
    }
}
~~~
- 작업 큐에 대한 순차적인 접근
- 내부적으로 살펴보면 순차적으로 처리해야만 하는 부분이있다
- 바로 작업큐에서 작업을 하나씩 뽑아내는 부분이다.
- ex) 큐의 상태를 안정적으로 유지하고자 락을 사용했다면, 특정 스레드가 큐에서 작업을 하나 뽑아내는 그시점에 역시 큐에서 작업을 가져가고자 하는 다른 모든 스레드는 큐를 독점적으로 사용할 수 있을때까지 대기해야만 한다. 따라서 작업큐와 관련된 부분에서는 ㅅ프로그램이 순차적으로 처리 될 수 밖에 없다.
- 단일 작업 하나가 실행되는 시간에는 Runnable 실행하는 시간뿐만 아니라 공유돼 있는 작업 큐에서 작업을 뽑아내는 필요한 시간도 포함돼 있다.
- 작업 큐로 LinkBlockingQueue 를 사용하고 있다면 LinkedList 보다 훨씬 확장성이 좋은 알고리즘을 사용하고 있기 때문에 시간이 훨씬 적게든다. 하지만 데이터를 한군데에 공유해두고 사용하는 모든 부분은 항상 순차적으로 처리해야만 한다.
- 자바 Runnable 작업은 항상 실행결과를 로그파일에 적어두거나 특정 데이터 구조에 실행결과를 쌓아두도록 돼있다
    - 이부분 역시 순차적으로 처리해야만 하는 부분
- **모든 병렬 프로그램에는 항상 순차적으로 실행돼야되는 부분이 존재한다. 만약 그런 부분이 없다고 생각한다면, 프로그램 코드를 다시 한번 들여다보라.**
  
### 예제 프레임웍 내부에 감춰져 있는 순차적 실행 구조

![KakaoTalk_Photo_2021-06-12-15-46-54](https://user-images.githubusercontent.com/38197944/121767776-7812dd80-cb95-11eb-95d7-3c9af065b975.jpeg)
- Queue 가 있을때 여러 스레드가 값을 하나씩 뽑아낸 다음 뭔가 작업을 실행하는 일을 계속 반복하는 간단한 어플리케이션의 실행 속도를 측정 결과를 볼 수 있다.
- 스레드 안전성이 보장된 두가지 Queue 구현 클래스 성능을 한번에 볼 수 있음
- 하나는 synchronizedList 메소드로 동기화한 LinkedList 클래스이고, 다른 하나는 ConcurrentLinkedQueue 클래스 이다.
- 각 실행단위가 동일한 양의 작업을 처리한다고 할때 단순히 적절한 큐 구현 클래스를 사용하는것만으로도 확장성을 크게 높일수 있다는 사실을 알수 잇다.
- ConcurrentLinkedQueue 클래스의 처리량은 계속 증가하다가 프로세서의 개수에 해당하는 수치에 다다르면 더이상 증가하지 않고 유지하는 형태를 보인다.
- 반대로 동기화된 LinkedList 클래스의 성능은 스레드가 3개 정도까지는 증가하다가 그이후에는 동기화 관련 부하가 늘어서 성능이 떨어진다.
- 차이점이 발생하는 원인은 바로 두개의 큐 구현 클래스가 작업을 순차적으로 처리하는 정도의 차이점에 원인이 있음을 알수 있다. 동기화된 LinkedList 클래스는 전체 큐의 상태에 하나의 락으로 동기화 하고 있으며, 따라서 offer 나 remove 메소드를 호출하는 동안 전체 큐가 모두 락에걸린다.
- 반대로 ConcurrentLinkedQueue 클래스는 정교한 큐 알고리즘 즉 개별링크 포인터마다 단일연산으로 업데이트 하는 방법을 사용해 대기상태에 들어가는 경우를 최소화 한다.
- 동기화된 LinkedList 는 추가 작업과 삭제작업이 모두 순차적으로 처리되어야 하지만 ConcurrentLinkedQueue 에서는 개별 포인터에 대한 업데이트 연산만 순차적으로 처리하면 된다.

### 정성적인 암달의 법칙 적용 방법
- 암달의 법칙을 사용하면 프로그램 내부에서 순차적으로 처리돼야만 하는 부분의 비율을 알고 있을때, 하드웨어를 추가함에 따라 얼만큼 처리 속도가 증가할 것인지를 수치화 해서 예측 할 수 있다.
- cpu가 많이 보급되면서 이제는 많은 프로세서를 장착한 시스템을 어렵지 않게 생각하게 되었다 이런 환경에서 장착된 하드웨어에서 확장성이 충분하다고 생각됐던 알고리즘이 훨씬 규모가 큰 시스템을 대상으로 본다면 지금까지 알지 못했던 확장성에서의 병목을 맞닥뜨리게 될 가능성도 높다.
- 어느 시점쯤에서 확장성의 한계가 나타날것인지 예측해볼수있다. 락의 적용 범위를 줄이는 방법 즉 락 분할 방법과 락 스트라이핑에 대해서 알아볼것이다.
- 락의 적용 범위를 줄이는 방법은 암달의 법칙이라는 측면에서 바라보면 락을 두개로 분할하는 정도로 다수의 프로세서를 충분히 활용하기 어렵다는 결론을 얻을수 있다.
- 하지만 락스트라이핑 방법을 사용할때는 프로세서의 수가 늘어남에 따라 분할 개수를 같이 증가시킬수 있기때문에 확장성을 얻을 수 있는 믿을만한 방법이라고 할 수 있다.
  

## 11.3 스레드와 비용
- 스레드를 사용하는 경우 병렬로 실행함으로써 얻을 수 잇는 이득이 병렬로 실행하느라 드는 비용을 넘어서야 성능을 향상 시킬수 있다.

### 컨텍스트 스위칭
- 하나의 스레드가 실행되다가 다른 스레드가 실행되는 순간 컨텍스트 스위칭이 일어난다.
- 컨텍스트 스위칭이 일어나는 상세한 구조를 보면 먼저 현재 실행중인 스레드의 실행상태를 보관해두고, 다음번에 실행되기로 스케쥴 된 다른 스레드의 실행상태를 다시 읽어들인다.
- 스레드를 스케쥴링을 하려면 운영체제와 JVM 내부의 공용 자료 구조를 다뤄야 한다는 문제가 있다.
- 운영체제와 JVM 역시 스케쥴 프로그램 스레드가 사용하는 것과 같은 CPU를 사용하고 있다.
- 따라서 운영체제나 JVM이 CPU를 많이 사용하면 할수록 실제 프로그램 스레드가 사용할 수 있는 CPU양을 줄어든다.
- 컨덱스트가 변경되면서 다른 스레드를 실행하려면 해당 스레드가 사용하던 데이터가 프로세서의 캐시 메모리에 들어 있지 않을 확률도 높다. 그러면 캐시에서 찾지 못한 내용을 다른 저장소에서 찾아와야 하기 때문에 원래 예정된 것 보다 느리게 실행되는 셈이다.
- 이런 경우에 대비하고자 대부분의 스레드 스케줄러는 실행 대기중인 스레드가 밀려있다고 해도 현재 실행중인 스레드에게 최소한의 실행시간을 보장해주는 정책을 취하고 있다.
- 그러면 컨텍스트 스위칭에 들어가는 시간과 비용을 나누는 효과를 볼 수 있고, 그결과 인터럽트 받지 않고 실행할수 있는 최소한의 시간을 보장받기떄문에 전체적인 성능이 향상되는 효과를 볼 수 있다.
- 대기 상태에 들어가는 연산을 많이 사용하는 프로그램(블로킹 I/O 사용하거나, 락 대기 시간이 길거나, 상태변수 값을 기다리는)은 CPU를 주로 활용하는 프로그램보다 컨텍스트 스위칭 횟수가 훨씬 많아지고 따라서 스케줄링 부하가 늘어나면서 전체적인 처리량이 줄어든다.
    - 넌블로킹 알고리즘을 사용하면 컨텍스트 스위칭에 소모되는 부하를 줄일 수 있다.
- 컨텍스트 스위칭 필요한 부하와 비용을 플랫폼마다 다름 대략 5000~10000 클럭 사이클 또는 마이크로 초 동안의 시간을 소모한다고 알려져 있다.
- 유닉스 시스템의 vmstat 명령이나 윈도우 시스템의 perfmon 유틸리티를 사용하면 컨텍스트 스위칭 일어난 횟수 확인 할 수 있음
- 커널 활용도가 10%가 넘는 높은 값을 갖기오 있다면 스케쥴링 부하가 걸린다는 의미 아마도 어플리케이션 내부에서 I/O나 락관련 동기화 부분때문에 대기 상태에 들어가는 부분이 원인일 가능성이 높다.

### 메모리 동기화
- synchronized 와 volatile 키워드를 사용해 얻을 수 있는 가시성을 통해 메모리 배리어라는 특별한 명령어를 사용 할 수 있다. 
- 메모리 배리어는 캐시를 플러시하거나 무효화 하고, 하드웨어와 관련된 쓰기 버퍼를 플러시하고, 실행 파이프 라인을 늦출 수도 있다. 
- 메모리 배리어를 사용하면 컴파일러가 제공하는 여러가지 최적화 기법을 제대로 사용할 수 없게 돼 간접적인 성능 문제를 가져 올 수 있다.
    - 메모리 배리어를 사용하면 명령어 재배치를 대부분 할 수 없기 때문이다.
- 동기화가 성능에 미치는 영향을 파악하려면 동기화 작업이 경쟁적인지, 비경쟁적인지를 확인해야한다.
- synchronized 키워드가 동작하는 방법은 비경쟁적인 경우에 최적화 돼있기 때문에 빠른경로의 비경쟁적인 동기화 방법은 대부분의 시스템에서 20~250 클럭 사이클을 사용한다고 알려져있다.
- 물론 클럭 사이클을 전혀 사용하지 않는것은 아니지만, 전반적인 어플리케이션 성능 측면에서 봤을때 영향이 없다고 할 수 있음.

~~~java
synchronized (new Object()){
    //작업 진행
}
~~~
- 아무런 의미가 없는 동기화 구문 이런코드는 금물! JVM 락을 사용하지 않는다.
- 최근 사용하는 JVM 은 대부분 다른 스레드와 경쟁할 가능성이 없다고판단되는 부분에 락이 걸려 있다면 최적화 과정에서 해당락을 사용하지 않도록 방지하는 기능을 제공하기도한다.
- 예를 들어 락을 거는 객체가 특정 스레드 내부에 한정되어있다면 해당 락을 다른 스레드에서 사용하며 경쟁 조건에 들어 갈 수 없기 때문에 JVM 은 해당 락은 무시하고 넘어간다.

~~~java
public String getStoogeNames(){
    List<String> stooges = new Vector<String>();
    stooges.add("Moe");
    stooges.add("Larry");
    stooges.add("Curly");
    return stooges.toString();
}
~~~
- 락 제거 대상
- 정교하게 만들어진 JVM의 경우 유출 분석을 통해 로컬 변수가 외부로 공개된적이 있는지 없는지 다시 말해 해당 변수가 스레드 내부에서만 사용되는지 판단하기도 한다.
- 허술한 JVM 에서 위의 코드를 사용할경우 add, toString을 호출하는 부분에서  4번 총 락을 잡게 된다.
- 정교한 고급컴파일러와 JVM은 stooges가 메소드 외부에 유출된 적이 없다는것을 판단하고 락을 4번이나 잡지 않는다. 빠르게 실행시킨다.
- 유출 분석을 사용하지 않는 경우라면 락확장 즉 연달아 붙어있는 여러개의 synchronized 블록을 하나의 락으로 묶는 방법을 사용하기도 한다.
- 락 확장 기능을 갖고있는 JVM 에서 위의 코드 실행한다면 add 메소드 3번 toString 호출 한번에 묶어 락을 한번만 확보하고 해제한다.
- 락 확장 기능을 사용하는 JVM은 락을 확보하고 해제하는 걸리는 시간과 synchronized 블록 내부의 작업에 걸리는 시간을 살펴보고 확장하는 것이 효율적이라고 판단되는 경우에만 확장하기도 한다.
- 락 확장 방법을 사용하면 동기화 관련 부하를 줄이는데 도움, 최적화 모듈이 좀더 큰 단위의 블록을 대상으로 추가적인 최적화 작업을 진행할 기회가 생기기도한다.
- **경쟁 조건에 들어가지 않는 동기화 블록에 대해서는 그다지 걱정하지 않아도 좋다. 동기화 블록의 기본적인 구조가 상당히 빠르게 동작 할 뿐만 아니라, JVM 수준에서 동기화와 관련한 추가적인 최적화 작업을 진행하기 떄문에 동기화 관련 부하를 줄이거나 아예 없애주기도 한다. 대신 경쟁조건이 발생하는 동기화 블록을 어떻게 최적화 할지 대해서 고민하자.**
- 특정 스레드에서 진행되는 동기화 작업으로 인해 다른 스레드의 성능이 영향을 받을 수 있다.
- 동기화 작업은 공유돼있는 메모리로 통하는 버스에 많은 트래픽을 유발 하기 때문이다. 공유 메모리로 통하는 버스는 제한적인 대역폭을 갖고 있으며 여러개의 프로세서가 공유한다.
- 특정 스레드가 동기화 작업을 진행하느라 공유 메모리로 통하는 버스의 대역폭을 꽉 잡고 있다면, 동기화 작업을 진행해야 할 다른 스레드는 성능이 떨어 질 수 밖에 없다.
- 
### 블로킹
- 락을 확보하지 못한 스레드는 항상 대기 상태에 들어가야한다.
- JVM은 스레드를 대기 상태에 둘때 두가지 방법을 사용한다.
- 첫번째는 스핀대기 spin waiting 락을 확보할때까지 계속 재시도하는 방법
- 두번째 방법은 운영체제가 제공하는 기능을 사용해 스레드를 실제 대기 상태로 두는 방법
- 두개 방법 가운데 어느쪽이 효율적이냐는 답은 컨텍스트 스위칭에 필요한 자원의 양과 락을 확보할때까지 걸리는 시간에 크게 좌우된다. 대기 시간을 놓고 보면 대기 시간이 짧은 경우에는 스핀 대기 방법이 효과적이고, 대기 시간이 짧은 경우네는 스핀 대기 방법이 효과적이고, 대기시간이 긴경우에는 운영체제의 기능을 효출하는 편이 효율적이라고 한다. 
- 일부 JVM은 이전에 실행된 패턴을 분석한 결과를 놓고 두가지 방법중에 효과적인 방법을 선택해 사용하기도 하지만 대부분의 경우 운영체제의 기능을 호출하는 방법을 사용한다.
- 락을 확보하지 못했거나 I/O 관련 작업을 사용중이라거나 기타 여러가지 조건에 걸려들어 스레드가 대기상태에 들어갈때는 두번의 컨텍스트 스위칭 작업이 일어나며, 이 과정에는 운영체제와 각종캐시등의 모듈이 연결돼 있다.
- 첫번째 컨텍스트 스위칭은 실행하도록 할당된 시간이전에 대기 상태에 들어가느라 발생하는것이고, 두번째는 락이나 기타 필요한 조건이 충족됬을때 다시 실행상태로 돌아오는 컨텍스트 스위칭이다.

## 11.4 락 경쟁 줄이기
### 락 구역 좁히기
~~~java

~~~

~~~java

~~~

### 락 정밀도 높이기

~~~java

~~~

~~~java

~~~

### 락 스트라이핑

~~~java

~~~

### 독점적인 락을 최소화하는 다른 방법

### CPU 활용도 모니터링

### 객체 풀링은 하지 말자

## 11.5 예제: Map 객체의 성능 분석
- 단일 스레드 환경에서 ConcurrentHashMap 은 동기화된 HashMap 보다 약간 성능이 빠르다.
- 병렬 처리 환경에서는 ConcurrentHashMap의 성능이 빛을 발한다.
- ConcurrentHashMap의 가장 많이 사용하는 기능이 현재 맵 내부에 갖고 있는 값을 찾아내 가져가는 연산이라고 가정하고 있으며, 여러개의 스레드에서 get 메소드를 연달아 호출하는 경우에 가장 빠른 속도를 낸다.
- 동기화된 HashMap 클래스가 속도가 떨어지는 가장 큰 이유는 맵 전체가 락으로 동기화돼 있다는 점이고, 한번에 하나의 스레드만 맵을 사용 할 수 있다.
- ConcurrentHashMap은 대부분의 읽기 연산에는 락을 걸지 않고 있으며 쓰기 연산과 일부 읽기 연산에는 락 스트라이핑을 활용하고 있다. 이런 기법에 힘입어 대부분이 경우 대기 상태에 들어가지 않고도 다수의 스레드가 동시에 ConcurrentHashMap의 기능을 사용 할 수 있다.
  
  ![KakaoTalk_Photo_2021-06-12-12-50-07](https://user-images.githubusercontent.com/38197944/121764162-bd76e100-cb7c-11eb-94f8-71b193279bb6.jpeg)
- ConcurrentHashMap, ConcurrentSkipListMap은 애초에 설계할때 멀티 스레드 환경에서 사용하는 것을 목표로 만들어졌고, SynchronizedMap 을 활용해 동기화 시킨 HashMap, TreeMap 은 아주 단순하게 강제로 동기화를 맞춘것이라고 볼수 있다.
- 성능을 측정하는 각 경우마다 N개의 스레드가 임의의 키를 선택한다음 그 키에 해당하는 값을 맵에서 읽어오는 단순한 코드 반복한다.
- ConcurrentHashMap, ConcurrentSkipListMap에 대한 결과를 보면 스레드 수가 늘어남에 따라 성능이 잘 따라와 준다는 사실을 알 수 있음, 스레드 개수가 늘어남에 따라 처리량도 같이 늘고 있다.
- SynchronizedMap으로 동기화 된 맵이 보여주는 성능 수치는 그다지 좋지않다.
- 단일 스레드로 동작할때는 ConcurrentHashMap과 대등한 속도를 보여주지만 경쟁 조건이 발생하지 않는 상황에서 경쟁이 발생하는 상황으로 넘어가면 성능이 급격하게 저하하는것을 볼수 있다.
- 락 경쟁을 제대로 막지 못하는 경우에 흔히 발생한다.
- 경쟁이 많이 발생하지 않는 상황에서는 연산하는데 필요한 시간이 실제 작업에 필요한 시간과 크게 차이 나지 않으며, 스레드가 추가될수록 성능도 함께 증가한다. 하지만 한번 경쟁이 발생하기 시작하면 연산에 필요한 시간의 대부분이 컨텍스트 스위칭과 스케줄링에 필요한 대기시간으로 소모되며, 스레드를 추가한다해도 성능을 거의 끌어올리지 못한다.

## 11.6 컨텍스트 스위치 부하 줄이기
- 실행과 대기의 두가지 상태를 옮겨다니는것을 컨텍스트 스위치라고한다.
- 서버 어플리케이션에서 대기 상태에 들어가기 쉬운 경우 
    - ex) 로그 메세지 생성하는 경우
- 컨텍스트 스위치 횟수를 줄이면 서버의 처리량에 어떤 변화가 있는지 2가지 로그 출력 방법 사용했을때 비교
- println 문장을 호출하는 경우

~~~java
public class LogWriter {
    private final BlockingQueue<String> queue;
    private final LoggerThread logger;

    public LogWriter(Writer writer) {
        this.queue = new LinkedBlockingQueue<>(CAPACITY);
        this.logger = new LoggerThread(writer);
    }
    
    public void start(){
        logger.start();
    }
    
    public void log(String msg) throws InterruptedException{
        queue.put(msg);
    }
    
    private class LoggerThread extends Thread{
        private final PrintWriter writer;
        ...
        public void run(){
            try{
                while (true)
                    writer.println(queue.take());
            }catch (InterruptedException ignored){}
            finally {
                writer.close();
            }
        }
    }
}
~~~
- 229쪽 LogWriter 와 같은 모습, 로그 출력 작업 백그라운드 스레드에 의해 진행되며, 실제로 로그 메세지를 출력하고자 했던 스레드는 실제로 로그를 출력하지 않는다.
  
- 2가지 방법 성능차이 남
    - 출려기되는 로그 메세지의 양이나 로그메세지를 몇개의 스레드에서 출력하는
    - 컨텍스트 스위치를 하는데 얼마만큼의 자원이 필요한지 등에 의해 차이가 발생한다.
- 로그 출력 기능에 걸리는 시간은 항상 I/O 스트림 클래스와 관련된 모든 작업 시간을 포함한다. 
- 즉 I/O 연산이 대기 상태에 들어가면 해당 스레드가 대기중인 시간까지 전체 작업 시간에 포함된다.
- 그러면 운영체제는 I/O 작업이 끝날떄까지 해당 스레드를 대기상태에 집어 넣는다.
- 스레드에 따라 달라질수 있음, 그렇기 때문에 서비스 시간이 늘어남
- 다수의 스레드가 동시다발적으로 로그메세지를 출력하고자 한다면 메세지를 출력하는 출력스트림 객체에 대한 락을 두고 경쟁이 발생할 수 있다.
- 그러면 블로킹 I/O의 경우 같이 스레드가 락을 확보하기 위해 대기상태에 들어가면서 컨텍스트 스위치가 발생하는 결과가 나타난다.
- 로그 메세지를 즉시 출력하는 방법은 I/O 연산과 스트림에 대한 락에 직접적으로 연결돼 있으며, 따라서 컨텍스트 스위치가 빈번하게 발생할 가능성이 높고 서비스 시간은 점점 늘어난다.
- 서비스 시간이 길어진다는 애기는 바로 누군가가 서비스 결과를 얻기 위해 오랫동안 기다리는다는 말과 같다.
    - 서비스 시간이 길어질수록 락 경쟁을 심화시킨다는 점
- 락을 오랫동안 확보하고 있을수록 락에 대한 경쟁이 발생할 가능성이 높아지기 때문에 락을 확보하고 있는 시간을 최대한 줄여야한다.
- 락을 놓고 경쟁하고 있다는 말을 컨텍스트 스위치가 많이 일어나고 있다는 말과 같음. 전반적인 성능이 저하 될수 밖에없다.
- 병렬 처리 시스템은 대부분의 락을 대상으로 경쟁이 발생하지 않는 경우에 훨씬 높은 성능을 보여준다.
  
- 요청을 처리하는 스레드의 외부로 I/O 작업을 뽑아내는 방법은 요청을 처리하는 평균시간을 줄여주는 좋은방법이다.
    - log 메소드를 호출하는 스레드는 더이상 출력 스트림에 대한 락을 확보할 필요도 없고 I/O 완료 될때 까지 대기하지 않아도 된다.
    - 출력할때 로그 메세지를 큐에 쌓아두는 즉시 리턴돼 본연의 작업을 진행 할 수 있다.
    - 반대로 메세지큐를 사용하기 위한 경쟁이 발생할 가능성이 높긴하지만, 메세지르 큐를 쌓는 put연산이 실제로 출력스트림에 메세지를 출력하는 연산보다 훨씬 가벼운 연산
    - 따라서 실제 상황에서 로그를 출력하고자 할때 스레드가 대기 상태에 들어갈 일이 거의 없고, 로그메세지를 출력하느라 컨텍스트 스위치가 발생할 확률도 줄일수 있다.
    - 작업이 실제로 처리되는 위치를 옮겼고, 로그 관련 I/O 작업을 모두 단 하나의 스레드에서 처리하도록 넘기고 있기 때문에 로그 출력 스트림을 공유하지 않아도 되고, 따라서 대기 상태에 들어 갈 수 있는 원인을 방지하고 있다.
- 이런 구조를 갖춰두면 스케줄링, 컨텍스트 스위칭, 락관리와 같은 각 부분에서 사용하는 자원의 양을 크게 줄일수 있기때문에 전반적인 성능을 높일 수 있다.

- 로그를 출력하고자 요청하는 다수의 스레드에서 발생할 I/O 연산을 단하나의 스레드에서 처리하도록 한군데로 몰아두는 일
    - ex) 불을 끄고자 할때 서로 양동이를 들고 뛰어다니는 경우, 줄을 맞춰 서서 양동이를 넘겨주는 방법
- 스레드 입장에서는 대기상태에 들어가거나 컨텍스트 스위치가 일어나는일이 원래 작업을 처리하는데 상당한 방해가 된다.

요약
- 멀티스레드를 사용하는 큰 이유중 하나가 바로 다중 CPU 하드웨어를 충분히 활용하고자 하는것이다.
- 암달의 법칙에 따르면 어플리케이션의 확장성은 반드시 순차적으로 실행돼야만 하는 코드가 전체에서 얼마만큼의 비율을 차지하냐에 달렸다고함
- 자바프로그램의 내부에서 순차적으로 처리해야만 하는 가장 주요한 부분은 바로 독점적인 락을 사용하는 부분이기 때문에 락으로 동기화하는 범위를 세분화해 정밀도를 높이거나 락을 확보하는 시간을 최소한으로 줄이는 기법을 사용해 락으 최소한만 사용해야한다.
- 그리고 독점적인 락 대신 독점적이지 않은 방법을 사용하거나 대기 상태에 들어가지 않는 방법을 사용하는 것도 중요하다.

## 참고
책 자바 병렬 프로그래밍 11장