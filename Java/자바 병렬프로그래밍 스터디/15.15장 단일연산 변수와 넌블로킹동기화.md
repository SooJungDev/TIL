## 15장 내용
- 15.1 락의 단점
- 15.2 병렬 연산을 위한 하드웨어적인 지원
- 15.3 단일 연산 변수 클래스
- 15.4 넌블럭킹 알고리즘

- Semaphore, ConcurrentLinkQueue와 같이 java.util.concurrent 패키지에 들어있는 다수의 클래스는 단순하게 synchronized 구문으로 동기화를 맞춰 사용하는것에 비교하면 속도도 빠르고 확장성도 좋다.
- 15장에서는 이와 같은 클래스의 성능이 좋아진 원인이라고 볼수 있는 단일 연산 변수와 같이 대기상태에 들어가지 않는 넌블로킹 동기화 기법을 살펴볼 예정이다.
- 넌블록킹 알고리즘은 락을 기반으로 하는 방법보다 설계와 구현이 모두 훨씬 복잡하며, 대신 확장성과 활동성을 엄청나게 높여준다.
- 넌블로킹 알고리즘은 훨씬 세밀한 수준에서 동작하며, 여러 스레드가 동일한 자료를 놓고 경쟁하는 과정에서 대기 상태에 들어가는 일이 없기때문에 스케줄링 부하를 대폭 줄여준다. 
- 데드락이나 기타 활동성 문제가 발생할 위험도 없다. 
- 락을 기반으로 하는 알고리즘은 특정 스레드가 락을 확보한상태에서 잠자기 상태에 들어가거나 반복문을 실행하면 다른 스레드는 그시간 동안 각자의 작업가운데 락이 필요한 부분을 전혀 실행할수 없다.
- 넌블로킹 알고리즘을 사용하는 경우에는 개별스레드에서 발생하는 오류의 의해 영향을 받는 일이 없다. 
- 자바 5.0부터는 AtomicInteger, AtomicReference등의 단일 연산변수를 사용해 넌블로킹 알고리즘을 효율적으로 구현할수 있게 됐다.
- 단일 연산 변수는 넌블로킹 알고리즘을 구현하는일이 아니라해도 더나은 volatile 변수의 역할만으로 사용할수도 있다 
- 단일 연산 변수는 volatile 변수와 동일한 메모리 유형을 갖고있으며 단일연산으로 값을 변경 할 수 있는 기능을 갖고있다.
- 이런 특성을 사용해 숫자카운터, 일련번호생성기, 통계수치 추출기등으로 활용하면 락 기반의 구조에 비해 높은 확장성을 얻을 수 있다.

## 15.1 락의 단점
- 공유된 상태에 접근하려는 스레드에 일관적인 락 구조를 적용해 동기화하면 특정 변수를 보호하고 있는 락을 확보한 스레드가 해당변수에 대한 독점적인 접근 권한을 갖게되며, 변수의 값을 변경했다고 하면 다음 스레드가 락을 확보했을때 모든 변경된 사항을 완벽하게 볼 수 있다.
- 최근 사용하는 JVM은 스레드간의 경쟁이 없는 상태에서 락을 확보하는 부분을 최적화하는 기능을 갖고있으며 락을 해제하는 부분도 굉장히 효율적이다 하지만 락을 확보경쟁이 벌어지는 상황에서는 JVM 역시 운영체제의 도움을 받는다.
- 스레드의 실행을 중단했다가 계속해서 실행하는 작업은 부하를 발생시키며 일반적으로 적지 않은 시간동안 작업이 중단되게 된다.
- 락을 기반으로 세밀한 작업을 주로 하도록 구현돼있는 클래스는 락에 대한 경쟁이 심해질수록 실제로 필요한 작업을 처리하는 시간대비 동기화 작업에 필요한 시간의 비율이 상당한 수치로 높아질 가능성이 있다.
- volatile 변수는 락과 비교했을때 컨텍스트 스위칭이나 스레드 스케줄링과 아무런 연관이 없기 때문에 락보다 훨씬 가벼운 동기화 방법이라고 볼수 있다.
- volatile 변수는 락과 비교 했을때 가시성 측면에서는 비슷한 수준을 보장하지만 복합연산을 하나의 단일 연산으로 처리할 수 있게 해주는 기능은 전혀 갖고 있지 않다.
- 따라서 하나의 변수가 다른 변수와 관련된 상태로 사용해야 하거나, 하나의 변수라도 해당 변수의 새로운 값이 이전값과 관련이 잇다면 volatile 변수를 사용할 수 없다.
    - 이러한 특성 때문에 volatile 변수로는 카운터나 뮤텍스를 구현 할 수 없다.
- volatile 변수를 사용할수 잇는 부분이 상당히 제한된다.
- ex) ++i 
- 변수의 현재 값을 읽어오고 읽어온값에 1을 더하고 더해진 변수에 다시 설정하는 세가지 연산의 조함 구현
- 여러 스레드가 동작하는 과정에서 값을 제대로 변경하려면 읽고 변경하고 쓰는 세가지 작업 전체가 하나의 단일 연산으로 동작해야한다.


~~~java
@ThreadSafe
public final class Counter{
    @GuardedBy("this") private long value = 0; // 단하나의 변수
    // Counter 클래스의 상태는 value 변수만 보면 알수 있다.

    public synchronized long getValue(){
        return value;
    }

    public synchronized long increment(){
        if(value == Long.MAX_VALUE)
            throw new IllegalStateException("counter overflow");
        return ++value;
    }
}
~~~
- 자바 모니터 패턴을 활용해 스레드 안전성을 확보한 카운터 클래스 
- 지금까지는 두개 이상의 작업을 하나의 단일 연산으로 묶으려면 98쪽에서 봤던 counter 예제와 같이 락을 사용해야만 했다.
- Counter 클래스는 스레드에 안전한 구조를 갖고 있으며 스레드간의 경쟁이 없거나 많지 않은 상황에서는 성능이 괜찮게 나온다.
- 하지만 경쟁이 심한 상황이 되면 컨텍스트 스위칭 부하와 함께 스케줄링 관련 지연 현상이 발생하면서 성능이 떨어진다. 
- 락을 짧은 시간만 사용하기 때문에 그 작업을 위해서 스레드를 대기상태에 들어가게 하는일이 굉장히 단점이 될 수 있다.
- 락기반의 동기화 방법에는 또다른 단점도 있다. 스레드가 락을 확보하기 위해 대기하고 있는 상태에서 대기중인 스레드는 다른 작업을 전혀 못한다. 
- 락을 확보하고 있는 스레드의 작업이 지연되면 해당 락을 확보하기 위해 대기하고 있는 모든 스레드의 작업이 전부 지연된다.
- 락을 확보하고 지연되는 스레드의 우선순위가 떨어지고 대기상태에 있는 우선순위가 높다면 프로그램 성능에 심각한 영향을 미칠 수 있으며 이런 현상을 우선순위역전(priority inversion)이라고 부른다
- 대기중인 스레드의 우선순위가 높음에도 불구하고 락이 해제될때까지 대기해야 하며, 결과적으로 락을 확보하고 있는 스레드의 우선순위보다 더 낮은 우선 순위를 가진것처럼 동작한다.
- 최악의 상황에서는 락을 확보하고 있던 스레드가 영원히 멈추는 상황이 발생하면 대기중이던 모든 스레드 역시 영원히 대기하고 동작을 멈추게 된다.
- 카운터값을 증가시키는등의 세밀한 작은 연산을 동기화하기에는 락이 너무 무거운방법
- volatile 변수와 같이 가벼우면서 단일 연산 조건까지 충족시키는 그런방법을 사용하는것이 좋음
- 요즘 사용되는 대부분의 프로세서는 그와 같은 방법을 제공하고 있다.

## 15.2 병렬 연산을 위한 하드웨어적인 지원
- 초기 프로세스는 확인하고 값을 설정값을 읽어와서 증가,치환등의 단일 연산을 하드웨어 적으로 제공했으며, 이런 연산을 기반으로 더 복잡한 병렬클래스를 쉽게 만드는데 도움이 되는 뮤텍스를 충분히 구현 할 수 있었다.
- 최근에는 거의 모든 프로세서에서 읽고 변경하고 쓰는 단일 연산을 하드웨어적으로 제공하고 있다.
- 예를들어 비교하고 치환 compare-and-swap, LL(load-link) / SC(store-conditional) 등의 연산등이 있다.
- 운영체제와 JVM은 모두 이와 같은 연산을 사용해 락과 여러가지 병렬자료구조를 작성했지만, 자바 5.0 이전에는 자바 클래스에서 직접 이런 기능을 사용 할 수 는 없엇다.
  
### 비교후 치환 
- 비교후 치환 CAS(Compare and Swap) 연산에는 3개의 인자를 넘겨주는데, 작업할 대상 메모리의 위치인 V, 예상하는 기존값인 A, 새로 설정할 값인 B의 3개이다.
- CAS연산은 V 위치에 있는 값이 A와 같은 경우에는 B로 변경하는 단일 연산이다.
- 만약 이전값이 A(기존값)와 달랐다면 아무런 동작하지 않는다. 그리고 값을 B(새로 설정할 값)로 변경했건 못햇건간에 어떤 경우라도 현재 V(작업할 대상의 메모리 위치)값을 리턴한다.
- CAS 연산은 낙관적인 기법이다. 다시말해 일단 성공적으로 치환할 수 잇을것이라고 희망하는 상태에서 연산을 실행해보고 값을 마지막으로 확인한 이후에 다른 스레드가 해당 하는 값을 변경했다면 그런 사실이 있는지를 확인하자는 의미이다.

~~~java
@ThreadSafe
public class SimulatedCAS {
    @GuardedBy("this")
    private int value;

    public synchronized int get() {return value;}

    public synchronized int compareAndSwap(int expectedValue, int newValue) {
        int oldValue = value;
        if (oldValue == expectedValue) { value = newValue; }
        return oldValue;
    }

    public synchronized boolean compareAndSet(int expectedValue, int newValue) {
        return (expectedValue == compareAndSwap(expectedValue, newValue));
    }
}
~~~
- CAS 연산을 그대로 구현한 코드
- 만약에 여러 스레드가 CAS연산을 사용해 한 변수의 값을 변경하려고 한다면, 스레드 가운데 하나만 성공적으로 값을 변경할 것이고, 다른 나머지 스레드는 모두 실패한다.
- 대신 값을 변경하지 못했다고 해서 락을 확보하는것처럼 대기상태에 들어가는 대신 이번에는 값을 변경하지 못햇지만 다시 시도할 수 있다고 통보받는 셈이다.
- CAS 연산에 실패한 스레드도 대기상태에 들어가지 않기 때문에 스레드마다 CAS연산을 다시 시도할것인지, 아니면 다른 방법을 취할 것인지, 아니면 아예 아무 조치도 취하지 않을 것인지 결정할 수 있다. 이와 같이 CAS연산의 유연성 때문에 락을 사용하면서 발생할 수 밖에 없었던 여러가지 활동성 문제를 미연에 방지할 수 잇다
- CAS를 활용하는 일반적인 방법은 먼저 V(작업할 대상 메모리의 위치)에 들어있는 값 A(기존값)를 읽어내고 A(기존값)값으로 새로운 B(새로 설정할 값)값을 만들어내고 CAS 연산을 사용해 V(작업할 대상 메모리의 위치에 들어있는 A(기존값)의 값을 B(새로 설정할 값)값으로 변경하도록 시도한다.
- 그러면 다른 스레드에서는 그사이에 V(작업할 대상 메모리의 위치)의 값을  A(기존값)가 아닌 다른값으로 변경하지 않은한 CAS연산이 성공하게된다.
- CAS 연산을 사용하면 다른 스레드와 간섭이 발생했는지를 확인할 수 있기 때문에 락을 사용하지 않으면서도 읽고 변경하고 쓰는 연산을 단일 연산으로 구현해야 한다는 문제를 간단하게 해결해준다.

### 넌블로킹 카운터
~~~java
@ThreadSafe
public class CasCounter {
    private SimulatedCAS value;

    public int getValue() {
        return value.get();
    }

    public int increment() {
        int v;
        do {
            v = value.get();
        } while (v != value.compareAndSwap(v, v + 1));
        return v + 1;
    }
}
~~~
- CAS 기반으로 구현한 넌블로킹 카운터 클래스
- CAS 연산을 사용해 대기상태에 들어가지 않으면서도 스레드 경쟁에 안전한 카운터 클래스이다.
- 카운터 증가 연산은 표준적인 형태를 그대로 따른다. 즉 이전 값을 가져오고, 1을 더해 새로운 값으로 변경하고 CAS 연산으로 새 값을 설정한다. 만약 CAS 연산이 실패한다면 그 즉시 전체 작업을 재시도한다.
- CasCounter 클래스는 대기 상태에 들어가는 일이 없는데 그 대신 다른 스레드에서 역시 같은 카운터 객체를 계속해서 업데이트하고 있다면 여러차례 재시도 해야 할수도 있다.
- 실제 사용한 예를 보면 많지 않은 양의 경쟁이 있는 상황에서도 CAS 기반의 클래스가 락 기반의 클래스보다 성능이 훨씬 좋고 락이 없는 경우에도 락 기반의 방법보다 나은 경우가 있다.
- 경쟁이 없는 상태에서 락을 확보하는 가장 빠른 경로를 생각해보면 최소한의 한번의 CAS 연산이 실행돼야 하고 락과 관련된 기본적인 작업 몇가지도 함께 실행해야 한다.
- 따라서 락 기반으로 구현한 카운터 클래스에서 가장 최적의 조건으로 실행되는 경우에도 CAS 기반의 카운터 클래스에서 일반적인 경우보다 더 많은 작업을 하는 셈이다.
- CAS 연산은 대부분 성공하는 경우가 많기 때문에 하드웨어에서 분기 지점과 흐름을 예측해 코드에 들어있는 while 반복문을 포함한 복잡한 논리적인 작업 흐름 구조에서 발생할 수 있는 부하를 최소화할수 있다.
- 락기반의 프로그램을 보면 언어적인 문법은 훨씬 간결하다. 락을 사용하면 JVM 내부에서 상당히 복잡한 코드 경로를 따라 실행하게 되고 운영체제 수준의 락이나 스레드대기, 컨텍스트 스위칭등의 기능을 불러다 쓰기도한다.
- CAS 연산을 프로그램에서 직접 사용하면 JVM 에서 특별한 루틴을 실행해야 할 필요도 없고, 운영체제의 함수를 호출해야할 필요도 없고 스케줄링 관련 작업을 따로 조절해야할 필요도 없다.
- 어플리케이션 수준에서는 코드가 더복잡해보이지만 JVM 이나 운영체제 입장에서는 훨씬 적응양의 프로그램만 실행하는 셈이다.
- CAS 연산의 가장 큰 단점은 호출하는 프로그램에서 직접 스레드 경쟁 조건에 대한 처리를 해야한다는점이 있는데 반면 락을 사용하면 락을 사용할 수 있을때까지 대기상태에 들어가도록 하면서 스레드 경쟁문제를 알아서 처리해준다는 차이점이 있다.
- CAS 연산의 성능은 프로세서마다 크게 차이가 난다.
- 스레드 간의 경쟁이 없는 상태에서 락을 가장 빠른 경로로 확보하고 해제하는데 드는 자원은 CAS 연산을 사용할때보다 약 2배정도 된다고 보면 무리가 없다.

### JVM에서의 CAS 연산 지원
- 자바 5.0 부터는 int, long 그리고 모든 객체의 참조를 대상으로 CAS 연산이 가능하도록 기능이 추가됐고, JVM은 CAS 연산을 호출받았을때 해당 하는 하드웨어에 적당한 가장 효과적인 방법으로 처리하도록 돼 있다.
- CAS 연산을 직접 지원하는 플랫폼의 경우라면 자바 프로그램을 실행할때 CAS 연산 호출부분을 직접 해당하는 기계어 코드로 변환해 실행한다
- 하드웨어에서 CAS 연산을 지원하지 않는 최악의 경우에는 JVM 자체적으로 스핀락을 사용해 CAS 연산을 구현한다. 이와 같이 저수준의 CAS 연산은 단일연산 변수 클래스 즉 AtomicIntger 와 같이 java.util.concurrent.atomic 패키지의 AtomicXxx 클래스를 통해 제공한다
- java.util.concurrent 패키지의 클래스 대부분을 구현할떄 이와같은 AtomicXxx 클래스가 직간접적으로 사용됐다.
  
## 15.3 단일 연산 변수 클래스
- 단일 연산 변수 atomic variable 는 락보다 훨씬 가벼우면서 세밀한 구조를 갖고 있으며, 멀티프로세서 시스템에서 고성능의 병렬프로그램을 작성하고자 할때 핵심적인 역할을 한다.
- 단일 연산 변수를 사용하면 스레드가 경쟁하는 범위를 하나의 변수로 좁혀주는 효과가 있으며 이정도의 범위는 프로그램에서 할수 있는 가장 세밀한 범위이다.
- 경쟁이 없는 상태에서 단일 연산 변수의 값을 변경하는 실행 경로는 락을 확보하는 가장 빠른 코드 실행경로보다 느릴 수 없으며, 대부분 단일 연산 변수쪽이 더 빠르게 실행된다.
- 따라서 락 대신 단일 연산 변수를 기반의 알고리즘으로 구현된 프로그램은 내부의 스레드가 지연되는 현상이 거의 없으며, 스레드간의 경쟁이 발생한다 해도 훨씬 쉽게 경쟁 상황을 헤쳐나갈 수 있다.
- 단일 연산 변수 클래스는 volatile 변수에서 읽고 변경하고 쓰는것과 같은 조건부 단일 연산을 지원하도록 일반화한 구조이다.
- AtomicInteger 클래스는 int 값을 나타내며, 일반적인 volatile 변수로 사용할때 변수의 값을 읽거나 쓰는 연산과 동일한 기능을하는 get, set메소드를 제공한다. 
- 또한 단일 연산으로 실행되는 compareAndSet 메소드도 제공하며, 편의 사항인 단일 연산을 값을 더하거나 , 증가, 감소시키는 등의 메소드도 제공한다.
- AtomicInteger 는 Counter클래스와 굉장히 비슷한 모습을 갖고있다. 하지만 동기화를 위한 하드웨어의 기능을 직접적으로 활용할수 있기 때문에 경쟁이 발생하는 상황에서 훨신 높은 확장성을 제공한다.
- 일단 12개의 단일 연산 변수 클래스가 제공되며, 대략 일반변수,필드 업데이터, 배열, 그리고 조합 변수의 4개의 그룹으로 나눠 볼수 있다.
- 가장 많이 사용하는 형태는 일반변수의 형태를 그대로 갖고있는 AtomicInteger, AtomicLong, AtomicBoolean, AtomicReference 클래스이다. 
- 네가지 모두 CAS연산을 제공하며  AtomicInteger, AtomicLong은 간단한 산술기능도 제공한다.
- 단일 연산 배열 변수 클래스는 배열의 각 항목을 단일 연산으로 업데이트 할 수 있도록 구성돼 있는 배열 클래스이다.
- 단일 연산 배열 클래스는 배열의 각 항목에 volatile 변수와 같은 구조의 접근 방법을 제공하며 일반적인 배열에서는 제공하지 않는 기능이다.
- 일반적인 배열의 변수가 volatile 이라 해도 배열 변수 자체에 대한 참조가 volatile 일뿐 각 항목까지 volatile 특성을 갖고 있지는 않다.
- 단일 연산 변수가 Number 클래스를 상속받고 있기는 하지만 Interger, Long과 같은 클래스는 상속받지 않고 있다
- Interger, Long과 같은 클래스는 변경이 불가능한 클래스이지만 AtomicInteger, AtomicLong과 같은 단일연산 클래스는 그 값을 변경할 수 있는 특징이 있기 때문이다. 단일 연산 클래스 또한 hashCode, equals 메소드를 재정의하고 있지는 않으며, 모든 인스턴스가 서로다르다.
- 내부 값을 변경할 수 있는 모든 클래스가 그렇지만 해시값을 기반으로 하는 컬렉션 클래스에 키값으로 사용하기에는 적절하지 않다는점도 잊지말자.

### 더나은 volatile 변수로의 단일 연산 클래스
- 114쪽의 NumberRange 클래스를 보면 큰 값과 작은 값을 갖고 있는 변경 불가능한 변수에 대한 volatile 참조만으로는 안전하게 구현할 수 없으며, 범위 제한 값에 단일 연산 변수를 사용한다해도 마찬가지다. 
- 범위라는 조건은 항상 두 변수의 값을 동시에 사용해야하며 필요한 조건을 만족하면서 그와 동시에 양쪽 범위 값을 동시에 업데이트 할 수 없기 때문에 volatile 참조를 사용하거나 AtomicInteger를 사용한다 해도 확인하고 동작하는 연산을 안전하게 수행할 수 없다.

~~~java
public class CasNumberRange {
    @Immutable
    private static class IntPair{
        final int lower; // 불변 조건 : lower <= upper
        final int upper;
        ...
    }
    
    private final AtomicReference<IntPair> values = new AtomicReference<>(new IntPair(0,0));
    
    public int getLower() {
        return values.get().lower;
    }
    
    public int getUpper(){
        return values.get().upper;
    }
    
    public void setLower(int i){
        while (true){
            IntPair oldv = values.get();
            if(i>oldv.upper)
                throw new IllegalArgumentException("Can't set lower to"+i+"> upper");
            IntPair newv = new IntPair(i, oldv.upper);
            if(values.compareAndSet(oldv, newv))
                return;
        }
    }
    
    // setUpper 메소드도 setLower 와 비슷하다
}
~~~
- CAS 를 사용해 다중변수의 안정성을 보장하는 
- CasNumberRange 클래스는 범위 양쪽에 해당하는 숫자 두개를 갖고있는 IntPair 클래스에 AtomicReference 클래스를 적용했다
- 그리고 compareAndSet 메소드를 사용해 NumberRange와 같은 경쟁 조건이 발생하지 않게 하면서 범위를 표현하는 값 두개를 한꺼번에 변경 할 수 있다.

### 성능 비교: 락과 단일 연산 변수
- 락과 단일 연산 변수 간의 확장성의 차이점을 확인할 수 있도록 여러가지 방법으로 구현한 난수발생기의 처리 속도를 비교하는 벤치 마크 테스트를 준비했다.
- 난수 발생기는 항상 이전 결과 값을 내부 상태로 보존하고 있어야 한다.
- 난수 발생기 테스트 프로그램은 각각의 함수를 계속해서 호출하며, 매번 반복할때마다 난수를 하나를 생성하고(난수 발생 작업은 공유된 seed 변수의 값을 읽어와서 변경하는 형태로 구성돼 있다.), 스레드 내부의 값만을 사용해 복잡한 작업에 해당하는 반복 작업도 수행한다.
- 이렇게 구성돼 있는 이유는 공유된 자원을 놓고 동작하는 부분과 스레드 내부의 값만 갖고 동작하는 부분을 함께 갖고 있는 일반적인 작업 형태를 묘사하기 위함이다.

~~~java
@ThreadSafe
public class ReentrantLockPseudoRandom extends PesudoRandom {
    private final Lock lock = new ReentrantLock(false);
    private int seed;

    ReentrantLockPseudoRandom(int seed) {
        this.seed = seed;
    }

    public int nextInt(int n) {
        lock.lock();
        try {
            int s = seed;
            seed = calculateNext(s);
            int remainder = s % n;
            return remainder > 0 ? remainder : remainder + n;
        } finally {
            lock.unlock();
        }
    }
}
~~~
- ReentrantLock 을 사용해 구현한 난수발생기
  

~~~java
@ThreadSafe
public class AtomicPseudoRandom extends PseudoRandom {
    private AtomicInteger seed;

    public AtomicPseudoRandom(int seed) {
        this.seed = new AtomicInteger(seed);
    }

    public int nextInt(int n) {
        while (true) {
            int s = seed.get();
            int nextSeed = calculatorNext(s);
            if (seed.compareAndSet(s, nextSeed)) {
                int remainder = s % n;
                return remainder > 0 ? remainder : remainder + n;
            }
        }
    }
}
~~~
- AtomicIntger 를 사용해 구현한 난수 발생기

- 그림 15.1, 15.2를 보면 매번 반복될때마다 각각 적은 양과 많은 양에 해당하는 작업을 처리하는 경위의 성능을 볼수 있다.
- 스레드 내부의 데이터만으로 처리하는 작업량이 처리하는 경우의 성능을 볼 수 있다.
- 스레드 내부의 데이터만으로 처리하는 작업량이 적은 경우에는 락이나 단일 연산 변수 쪽에서 상당한 경쟁 상황을 겪고, 반대로 스레드 내부의 작업량이 많아지면 상대적으로 락이나 단일 연산 변수에서 경쟁 상황이 덜 벌어진다.
- 경쟁 상황이 많은 상황에서는 단일 연산 변수보다 락이 더 빠르게 처리되는 모습을 볼 수 있지만 훨씬 실제적인 경쟁 상황에서는 단일 연산 변수가 락보다 성능이 더 좋다.
- 이런 현상은 락 특성때문에 나타난다.
- 즉 락을 두고 경쟁이 발생하면 대기 상태에 들어가는 스레드가 나타나는데 일부 스레드가 대기 상태에 들어가면 전체적인 CPU 사용률과 공유된 메모리 버스의 동기화 트래픽이 줄어드는 효과에 의해 처리 속도가 높아진다.
- 단일 연산 변수를 사용하면 경쟁 조건ㄴ에 대한 처리 작업의 책임이 경쟁하는 스레드에게 넘어간다.
- AtomicPseudoRandom 클래스는 경쟁이 발생하면 그 즉시 재시도하는것으로 대응하며, 일반적으로 괜찮은 방법이긴 하지만 경쟁이 심한 경우에는 경쟁이 계속해서 심하게 만드는 요인이 되기도 한다.
- 정상적인 프로그램에서는 아무일도 하지 않으면서 락이나 단일 연산 변수에 경쟁상황만 만들어내는 경우는 없다봐야한다.
- 실제로 단일 연산 변수는 일반적인 경쟁 수준에서 경쟁상황을 더 효율적으로 처리하기 때문에 단일 연산 변수가 락에 비해서 확장성이 좋다.
- 경쟁이 적거나 보통의 경쟁수준에서는 단일 연산 변수를 사용해야 확장성을 높일 수 잇다.
- 경쟁 수준이 아주 높은 상황에서는 락을 사용하는 쪽이 경쟁에 더 잘 대응하는 모습을 보인다.
- ThreadLocal 을 사용하면 락이나 단일 연산 변수를 사용하는 구조에서 하나의 값을 모든 스레드가 공유하는것과 달리 각 스레드는 서로 각자에게 소속된 난수만을 볼수 있다.
- 결국 상태변수를 공유하지 않고 동작하는 방법이 있다면 최대한 공유하지 않는 쪽을 더 낫다는 사실을 보여준다.
- 스레드간의 경쟁을 최대한 적절하게 처리하면 확장성을 어느정도 항상시킬수 잇다
- 하지만 최종적으로 확장성을 가장 높일 수 있는 방법은 스레드간의 경쟁이 발생하지 않도록 미연에 방지하는 방법이라는 점을 알아두자.

## 15.4 넌블럭킹 알고리즘
- 특정 스레드에서 작업이 실패하거나 또는 대기상태에 들어가는 경우에, 다른 어떤 스레드라도 그로 인해 실패하거나 대기 상태에 들어가지 않는 알고리즘을 넌블로킹 알고리즘이라고 한다.
- 또한 각 작업 단계마다 일부 스레드는 항상 작업을 진행할 수 있는 경우 락 프리 알고리즘이라고 한다.
- 스레드 간의 작업 조율을 위해 CAS 연산을 독점적으로 사용하는 알고리즘을 올바로 구현한 경우에는 사용하는 알고리즘을 올바로 구혀 ㄴ한 경우에는 대기 상태에 들어가지 않는 특성과 락 프리 특성을 함께 가지게 된다.
- 여러스레드가 경쟁을 한다해도 소호한 하나의 스레드는 반드시 성공하기 때문에 성공한 스레드는 작업을 진행할수 있다.
- 넌블로킹 알고리즘은 데드락이나 우선순위 역전등의 문제점이 발생하지 않는다.

### 넌블러킹 스택
- 넌블로킹 알고리즘을 구성할때 가장 핵심이 되는 부분은 바로 데이터의 일관성을 유지하면서 단일 연산 변경 작업의 범위를 단 하나의 변수로 제한하는 부분이다.
- 큐와 같이 연결된 구조를 갖는 컬렉션 클래스에서는 상태 전환을 개별적인 링크에 대한 변경 작업이라고 간주하고 AtomicReference 로 각 연결 부분을 관리해서 단일 연산으로만 변경할 수 있도록 하면 어느정도 구현이 가능하다.
- 스택은 연결 구조를 갖는 자료구조 가운데 가장 간단한 편에 속한다.
- 각항목은 각자 단 하나의 다른 항목만을 연결하고 있고, 반대로 각 항목은 단 하나의 항목에서만 참조된다.
~~~java
@ThreadSafe
public class ConcurrentStack<E> {
    AtomicReference<Node<E>> top = new AtomicReference<>();

    public void push(E item) {
        Node<E> newHead = new Node<E>(item);
        Node<E> oldHead;
        do {
            oldHead = top.get();
            newHead.next = oldHead;
        } while (!top.compareAndSet(oldHead, newHead));
    }

    public E pop() {
        Node<E> oldHead;
        Node<E> newHead;
        do {
            oldHead = top.get();
            if (oldHead == null) { return null; }
            newHead = oldHead.next;
        } while (!top.compareAndSet(oldHead, newHead));
        return oldHead.item;
    }

    private static class Node<E> {
        public final E item;
        public Node<E> next;

        public Node(E item) {
            this.item = item;
        }
    }
}
~~~
- 트라이버(Treiber) 알고리즘으로 대기 상태에 들어가지 않도록 구현한 스택
- 예제15.6 ConcurrentStack 클래스는 단일 연산 참조를 사용해 스택을 어떻게 구현하는지 보여주는 좋은 예이다
- 스택 자체는 Node 클래스로 구성된 연결 리스트이며, 최초 항목은 top변수에 들어 있고 각 항목마다 자신의 값과 다음 항목에 대한 참조를 갖고있다.
- push 메소드에서는 새로운 Node 인스턴스를 생성하고 새 Node 의 next 연결값으로 현재의 top 항목을 설정한다음, CAS 연산을 통해 새로운 Node를 스택의 top으로 설정한다.
- CAS 연산을 시작하기전에 알고 있던 top 항목이 CAS 연산을 시작한 이후에도 동일한 값이었다면 CAS 연산이 성공한다.
- 반대로 다른 스레드에서 그사이에 top 항목을 변경했다면 CAS 연산이 실패하며, 현재의 top 항목을 기준으로 다시 새로운 Node 인스턴스를 top으로 설정하기 위해 CAS 연산을 재시도한다.
- CAS 연산이 성공하거나 실패하는 어떤 경우라 해도 스택은 항상 안전정인 상태를 유지한다.
- CasCounter, ConcurrentStack 클래스는 대기상태에 들어가지 않는 알고리즘의 여러가지 특성을 모두 보여주고 있다
- 즉 작업이 항상 성공하는것은 아니며, 재시도해야 할 수 도있다.
- ConcurrentStack에서와 같이 대기 상태에 들어가지 않는 알고리즘은 락과 같이 compareAndSet 연산을 통해 단일 연산 특성과 가시성을 보장하기 때문에 스레드 안전성을 보장한다.
- 특정 스레드에서 스택의 상태를 변경했다면 상태를 변경할때 volatile 쓰기 특성이 compareAndSet 연산을 사용해야만 한다.
- 특정 스레드에서 스택의 값을 읽어간다면 변경을 가할때와 동일한 AtomicReference 객체에 대해서 get 메소드를 호출하게되며, 이는 정확하게 volatile 읽기 특성을 갖고 있다.
- 따라서 어느 스레드에서건 스택의 내용을 변경하면 스택의 내용을 확인하는 모든 스레드가 변경된 내용을 즉시 볼 수 있다.
- 그리고 스택 내부의 리스트는 단일 연산으로 top 항목을 변경하거나 또는 다른 스레드와의 경쟁 관계에서 아예 실패하는 compareAndSet 메소드를 사용해 변경하도록 돼 있다.

### 넌블럭킹 연결 리스트
- 연결 큐는 리스트의 머리와 꼬리 부분에 직접적으로 접근 할 수 있어야 하기 때문에 스택보다 훨씬 복잡한 구조를 갖고 있다.
- 일단 머리와 꼬리 부분에 직접으로 접근하려면 각 항목에 대한 참조를 서로 다른 두개의 변수에 각자 보관해야한다. 따라서 꼬리 항목을 가리키는 참조가 두개가 존재하게 되는데, 하나는 현재 가장 마지막에 있는 항목의 next 값이고, 또하나는 직접 접근하기 위해 따로 보관하고 있는 변수이다.
- 새로 운 항목을 연결 큐에 추가하려면 마지막 항목을 가리키는 두개의 참조가 동시에 단일 연산으로 변경돼야 한다.
- 따라서 연결 큐를 대기 상태에 들어가지 않도록 구현할수 있는 알고리즘은 이와 같은 두가지 경우를 모두 처리 할 수 있어야 한다.
- 이와 같은 기능을 구현하려면 여러가지 전략을 동원해야 한다
- 첫번째로는 데이터 구조가 여러단계의 변경 작업을 거치는 과정을 포함해 언제라도 일관적인 상태를 유지하도록 해야 한다. 
- 그래야만 스레드 B가 등장하는 시점에 스레드 A가 값을 변경하고 있었다고 해도 현재 다른 스레드에서 변경작업을 진행중이라는 사실을 스레드 B가 알수 있어야 하며, 스레드 B가 하고자 하는 변경작업을 당장 시작하지 않도록 조율할 수 있어야한다.
- 이런 전략을 사용하면 일단 여러 스레드가 큐 내부의 데이터를 흐트러 뜨리지 않으면서 차례대로 데이터에 접근 할 수 있기는 하지만 만약 차례대로 작업중인 스레드 하나에서 오류가 발생한다면 다음 차례로 대기하던 스레드는 큐의 데이터를 사용하지 못하게 된다.
- 두번째 전략은 스레드 A가 값을 변경하는 와중에 스레드 B가 데이터 구조를 사용하고자 접근하는 경우에 스레드 A가 처리중인 작업을 마쳐야 한다는 사실을 알수 있는 충분한 정보를 데이터 구조에 넣어두는 방법이다.
- 마이클 스콧 알고리즘은 ConcurrentLinkedQueue 클래스에서도 사용하고 있다.
- 여러 종류의 큐 알고리즘이 그렇지만 없는 비어 있는 큐는 표식 또는 의미없는 노드만 갖고 있고, 머리와 꼬리변수는 이와 같은 표식 노드를 참조하고 있다.
- 꼬리 변수는 항상 표식노드, 큐의 마지막 항목, 또는 맨뒤에서 두번째 항목을 가리킨다.
- 그림 15.3을 보면 두개의 항목을 갖고있는 정상적인 또는 평온한 상태의 큐를 볼수 있다.
- 새로운 항목을 추가하려면 두개의 참조를 변경해야한다.
- 첫번째는 현재의 큐의 마지막 항목이 갖고있는 next 참조값을 변경해서 새로운 항목을 큐의 끝에 연결하는 작업이다 
- 두번째는 꼬리를 가리키는 변수가 새로 추가된 항목을 가리킨도록 참조를 변경하는 작업이다
- 이 두작업사이에서는 그림 15.4와 같이 중간상태에 놓이게 된다. 두번째 작업까지 처리하고 나면 큐는 다시 그림 15.5와 같은 평온한 상태로 돌아간다.
- 위에서 소개했던 두가지 전략을 모두 성공적으로 구현하고자 할때 꼭 필요한 전략이 있다.
- 즉 큐가 평온한 상태에 있을때 tail 변수가 가리키는 항목의 next 값이 null 이 아닌 값을 갖도록 하는 전략이다.
- 따라서 어느 스레드건 간에 tail.next 값을 확인해보면 해당큐가 어떤상태에 놓여 잇는지를 확인 할 수 있다. 또한 큐가 중간 상태에 있다는 사실을 알고나면 tail이 바로 다음 항목을 가리키도록 변경해서 다시 평온한 상태로 돌려놓을수 있다. 
- 따라서 어느 스레드가 항목을 새로 추가하는 작업을 하던간에 항상 원하는 작업을 제대로 끝마칠 수 있다.

~~~java
@ThreadSafe
public class LinkedQueue<E> {
    private static class Node<E> {
        final E item;
        final AtomicReference<Node<E>> next;

        public Node(E item, Node<E> next) {
            this.item = item;
            this.next = new AtomicReference<>(next);
        }
    }

    private final Node<E> dummy = new Node<>(null, null);
    private final AtomicReference<Node<E>> head = new AtomicReference<>(dummy);
    private final AtomicReference<Node<E>> tail = new AtomicReference<>(dummy);

    public boolean put(E item) {
        Node<E> newNode = new Node<>(item, null);
        while (true) {
            Node<E> curTail = tail.get();
            Node<E> tailNext = curTail.next.get();
            if (curTail == tail.get()) {
                if (tailNext != null) {
                    // 큐는 중간 상태이고, 꼬리이동
                    tail.compareAndSet(curTail, tailNext);
                } else {
                    // 평온한 상태에서 항목 추가 시도
                    if (curTail.next.compareAndSet(null, newNode)) {
                        // 추가 작업 성공, 꼬리 이동시동
                        tail.compareAndSet(curTail, newNode);
                        return true;
                    }
                }
            }
        }
    }
}
~~~
- 마이클 스콧 넌블로킹 큐 알고리즘 가운데 항목 추가 부분(Michael and Scott, 1966)
- LinkedQueue.put 메소드는 새로운 항목을 추가하기전에 먼저 해당하는 큐가 중간 상태인지를 확인한다.(단계 A)
- 만약 중간 상태에 있었다면 누군가 다른 스레드에서 해당하는 큐에 값을 추가하고 있었다는 의미이다(C와 D단꼐 사이의 상태)
- 이미 값을 추가하고 있는 다른스레드가 작업을 마무리 할때까지 기다리기보다 처리해야할 작업, 즉 꼬리 변수의 참조를 다음 항목으로 넘겨주는 작업을 대신 처리한다(단계 B)
- 작업을 대신 처리한 이후에도 다른 스레드가 또 값을 추가하기 시작했는지를 다시확인하고, 만약 그렇다면 꼬리 변수의 참조를 한번 더 이동시킨다.
- 이렇게 꼬리 변수의 참조를 끝까지 이동시켜 큐가 평온한 상태임을 확인한 이후에야 자신이 추가하려던 항목에 대한 작업을 시작한다.
- 새로 추가하는 항목을 큐의 끝에 연결시키는 단계 C에서는 CAS 연산을 사용하며, 두개 이상의 스레드가 동시에 각자의 항목을 큐에 연결시키려 하면 실패하는 스레드가 발생 할 수 있다.
- 하지만 실패하는 경우가 생긴다 해도 큐에 아무런 변경 사항을 가하지도 못했으며 현재 스레드는 꼬리 변수의 참조 값을 다시 읽어서 재시도하면 되기 때문에 큐의 상태에 아무런 문제가 생기지 않는다.
- 단계 C 에서 작업이 성공하면 일단 항목을 연결하는데 성공한 셈이다. 
- 단계 D에서는 두번째 CAS 연산을 실행하는데, 단계 D 의 작업은 항목을 새로 추가한 스레드뿐만 아니라 다른스레드에서도 처리할 수 있기때문에 일종의 정리 작업이라고 볼수 있겠다
- 단계 D에서 CAS 연산이 실패한다해도 재시도 할 필요가 없다
- 단계 B를 실행하던 다른스레드에서 정리작업을 이미 실행했기 때문이다
- 어느 스레드건 간에 큐에 값을 추가하기전에 tail.next 값을 확인해서 정리 작업이 필요한지를 확인하기 때문에 잘 동작한다. 만약 정리작업이 필요하다면 평온한 상태가 될때까지 정리 작업을 계속 처리하게 된다.

### 단일 연산 필드 데이터
~~~java
private class Node<E> {
    private final E item;
    private volatile Node<E> next;

    public Node(E item) {
        this.item = item;
    }
}

/*nextUpdater 의 compareAndSet 메소드를 통해 next 변수 값을 변경
성능을 높이기 위해서 
큐의 연결노드와 같이 자주 생성하면서 오래 사용하지 않는 클래스가 필요한 경우
AtomicReference라는 클래스의 인스턴스 역시 매번 생성하고 없애는 부하가 생기게된다.
Node 인스턴스를 매번 생성할때마다 AtomicReference 의 인스턴스를 함께 생성해야 할 필요성을 없앨 수 있으므로 추가 작업에 대한 부하가 줄어든다.*/
private static AtomicReferenceFieldUpdater<Node, Node> nextUpdater = AtomicReferenceFieldUpdater.newUpdater(
        Node.class, Node.class, "next");

~~~
- CocurrentLinkedQueue 클래스에서 단일 연산 필드 업데이터를 사용하는 모습
- ConcurrentLikedQueue 에서는 각 Node 인스턴스를 단일 연산 참조 클래스로 연결하는 대신 일반적인 volatile 변수를 사용해 연결하고 연결 구조를 변경할때는 예제15.8과 같이 리플렉션 기반의 
AtomicReferenceFieldUpdater 클래스를 사용해 변경한다.
- 단일 연산 필드 업데이터 클래스는 현재 사용중인 volatile 변수에 대한 리플렉션 기반의 뷰를 나타내며, 따라서 일반 volatile 변수에 대해 CAS 연산을 사용할 수 있도록 해준다.
- 단일 연산 필드 업데이터 클래스에는 생성 메소드가 없으며, 인스턴스를 생성하려면 생성 메소드를 호출하는 대신 newUpdater 라는 팩토리 메소드에 해당하는 클래스와 필드, 즉 변수의 이름을 넘겨서 생성할 수 있다.
- 필드 업데이트 클래스는 특정 인스턴스와 연결돼 있지 않으며, 한번만 생성하면 지정한 클래스의 모든 인스턴스에 들어 있는 지정 변수의 값을 변경할때 항상 사용된다.
- 업데이터 클래스에서 보장하는 연산의 단일성은 일반적인 단일 연산 변수보다 약하다 지정한 클래스이 지정변수가 업데이터 클래스를 통하지 않고 직접 변경되는 경우가 있다면 연산의 단일성을 보장 할 수 없다.
- 따라서 필드 업데이터 클래스로 지정한 변수에 대해 연산의 단일성을 보장하려면 모든 스레드에서 해당 변수의 값을 변경할때 compareAndSet 메소드나 기타 산술 연산 메소드를 사용해야만 한다. 
- 거의 모든 경우에는 일반적인 단이 ㄹ 연산 변수만 사용해도 충분하고, 단일 연산 필드 업데이트 클래스를 사용해야 하는 경우는 몇군데 불과하다.
- 단일 연산 필드 업데이터 클래스는 현재의 직렬화된 형태를 그대로 유지하면서 단일 연산 작업을 수행하고자 하는 경우에도 유용하게 사용할 수 있다.
  
### ABA 문제
- ABA 문제는 (주로 가비지 컬렉션이 없는 환경에)노드를 재상요하는 알고리즘에서 비교후 치환 연산을 고지식하게 사용하다보면 발생할 수 있는 이상 현상을 만한다.
- 하지만 간혹 V 변수의 값이 내가 마지막으로 A값이라고 확인한 이후 변경된적이 있는지 라는 질문에 답을 알아야 할 경우도 있다.
- 일부 알고르짐을 사용하다 보면 V 변수 값이 A에서 B로 변경됏다가 다시 A로 변경된 경우 역시 변경사항이 있덨다는 것으로 인식하고 그에 해당하는 재시도 절차를 밟아야 할 필요가 있기도하다
- 이와 같은 ABA 문제는 연결 노드 객체에 대한 메모리 관리 부분을 직접 처리하는 알고리즘을 사용할때 많이 발생한다.
- 연결리스트이 머리 변수가 이전에 확인했던 그 객체를 참조하고 있다는 사실만으로 해당 리스트의 내용이 변경되지 않앗다고 확신 할 수 없다.
- ABA 문제 쉬운 해결방법이 있다. 참조값 하나만 변경하는것이 아니라 참조와 버전 번호의 두가지 값을 한꺼번에 변경하는 방법이다. 버전 번호를 관리하면 값이 A에서 B로 변경됐다가 다시 A로 변경된 경우라고 해도 버전 번호를 보고 변경된 상태라는 점을 알 수 있다.
- AtomicStampedReference 클래스는 두개의 값에 대해 조건부 단일 연산 업데이트 기능을 제공한다.
- AtomicStampedReference 클래스는 객체의 대한 참조와 수자값을 함께 변경하며 버전번호를 사용해 
ABA 문제가 발생하지 않는 참조의 역할을 한다.
- AtomicMarkableReference 클래스 역시 이와 같이 유사하게 객체의 대한 참조와 불린값을 함께 변경하며, 일부 알고리즘에서 노드 객체를 그대로 놓아두지만 삭제된 상태임을 표시하는 기능으로 활용하기도 한다. 
  
### 요약
- 대기 상태에 들어가지 않는 넌 블로킹 알고리즘은 락 대신 비교후 치환 compare-and-swap 같은 저수준의 명령을 활용해 스레드 안전성을 유지하는 알고리즘이다.
- 이런 저수준의 기능은 특별하게 만들어진 단일 연산 클래스를 통해 사용 할 수 있으며, 단일 연산 클래스는 더 나은 volatile 변수로써 정수형 변수나 객체에 대한 참조등을 대상으로 단일 연산 기능을 제공하기도 한다.
- 넌블로킹 알고리즘은 설계하고 구현하기는 훨씬 어렵지만 특정조건에서는 훨씬 나은 확장성을 제공하기도 하고, 가용성 문제를 발생시키지 않는다는 장점이있다.
- JVM이나 플랫폼 자체의 라이브러리에서 대기상태에 들어가지 않는 알고리즘을 적절히 활용하는 범위가 넓어지면서 JVM 버전이 올라갈때마다 병렬프로그램의 성능이 계속해서 나아지고 있다.

## 참고
책 자바 병렬 프로그래밍 15장